// üìÅ Gestionnaire de fichiers JSON
// G√®re la sauvegarde et le chargement des donn√©es persistantes

const fs = require('fs');
const fsp = fs.promises;
const dataStore = require('../data');
const dbManager = require('./dbManager');

// Cr√©er un dossier s'il n'existe pas
async function ensureDir(p) {
	try {
		await fsp.mkdir(p, { recursive: true });
	} catch (e) {
		// Dossier existe d√©j√†, ignore
	}
}

// üíæ Charger les donn√©es persistantes (d√©tecte Cloud vs Local)
async function loadPersistedData() {
	console.log('[persistence] üîÑ Chargement des donn√©es persist√©es...');

	// üÜï SERVEUR LOCAL = SOURCE DE VERITE : TOUJOURS charger depuis JSON local d'abord
	await loadFromJSON();
	console.log('[persistence] ‚úÖ Donn√©es charg√©es depuis fichiers locaux');

	// Puis synchroniser intelligemment avec MongoDB si disponible (pour commandes clients + backup)
	if (dbManager.db) {
		console.log('[persistence] ‚òÅÔ∏è Synchronisation intelligente avec MongoDB...');
		await smartSyncWithMongoDB();
		console.log('[persistence] ‚úÖ Synchronisation termin√©e');
	} else {
		console.log('[persistence] ‚ÑπÔ∏è MongoDB non disponible - fonctionnement en mode local seulement');
	}
}

// üíæ Sauvegarder les donn√©es (Cloud = Stateless, Local = Statefull)
async function savePersistedData() {
	if (dbManager.isCloud) {
		// üÜï SERVEUR CLOUD : STATELESS - PAS de sauvegarde JSON locale
		// MAIS sauvegarde quand m√™me dans MongoDB pour les donn√©es re√ßues
		if (dbManager.db) {
			saveToMongoDB().catch(e => {
				console.error('[sync] ‚ö†Ô∏è Erreur sync MongoDB cloud:', e.message);
			});
		}
		return;
	} else {
		// SERVEUR LOCAL : Sauvegarde JSON locale + sync MongoDB
		try {
			await saveToJSON();
		} catch (e) {
			console.error('[persistence] ‚ùå Erreur sauvegarde JSON local:', e.message);
		}

		// Sync vers MongoDB (non-bloquant)
		if (dbManager.db) {
			saveToMongoDB().catch(e => {
				console.error('[sync] ‚ö†Ô∏è Erreur sync MongoDB:', e.message);
			});
		}
	}
}

// Fonction supprim√©e - le serveur cloud est maintenant stateless

// --- LOGIQUE MONGODB (CLOUD) ---

async function loadFromMongoDB() {
	try {
		console.log('[persistence] ‚òÅÔ∏è Chargement des donn√©es depuis MongoDB...');
		
		// Charger les commandes
		const orders = await dbManager.orders.find({}).toArray();

		// üÜï SOLUTION : Identifier les commandes confirm√©es par leur originalTempId
		const confirmedTempIds = new Set(
			orders
				.filter(o => o.id && o.originalTempId && o.source === 'pos')
				.map(o => o.originalTempId)
		);

		// üÜï Filtrer : exclure les commandes client qui ont d√©j√† √©t√© confirm√©es
		const filteredOrders = orders.filter(o => {
			// Si c'est une commande client avec tempId mais sans id, v√©rifier si elle a √©t√© confirm√©e
			if (o.tempId && (!o.id || o.id === null) && o.source === 'client') {
				if (confirmedTempIds.has(o.tempId)) {
					console.log(`[persistence] üßπ Commande client ${o.tempId} ignor√©e: d√©j√† confirm√©e (ID #${orders.find(oo => oo.originalTempId === o.tempId && oo.id)?.id})`);
					// Supprimer de MongoDB aussi
					dbManager.orders.deleteMany({ tempId: o.tempId }).catch(e =>
						console.error(`[persistence] ‚ö†Ô∏è Erreur suppression doublon: ${e.message}`)
					);
					return false;
				}
			}
			return true;
		});

		dataStore.orders.length = 0;
		dataStore.orders.push(...filteredOrders);
		
		// Charger les archives
		const archived = await dbManager.archivedOrders.find({}).toArray();
		dataStore.archivedOrders.length = 0;
		dataStore.archivedOrders.push(...archived);
		
		// Charger les factures
		const bills = await dbManager.bills.find({}).toArray();
		dataStore.bills.length = 0;
		dataStore.bills.push(...bills);
		
		const archivedBills = await dbManager.archivedBills.find({}).toArray();
		dataStore.archivedBills.length = 0;
		dataStore.archivedBills.push(...archivedBills);
		
		// Charger les services
		const services = await dbManager.services.find({}).toArray();
		dataStore.serviceRequests.length = 0;
		dataStore.serviceRequests.push(...services);
		
		// Charger les compteurs (un seul doc)
		const countersDoc = await dbManager.counters.findOne({ type: 'global' });
		if (countersDoc) {
			dataStore.nextOrderId = countersDoc.nextOrderId || 1;
			dataStore.nextBillId = countersDoc.nextBillId || 1;
			dataStore.nextServiceId = countersDoc.nextServiceId || 1;
			dataStore.nextClientId = countersDoc.nextClientId || 1;
		}
		
		// Charger les clients cr√©dit
		const clients = await dbManager.clientCredits.find({}).toArray();
		dataStore.clientCredits.length = 0;
		dataStore.clientCredits.push(...clients);
		
		console.log(`[persistence] ‚òÅÔ∏è ‚úÖ ${dataStore.orders.length} commandes et ${dataStore.clientCredits.length} clients charg√©s depuis MongoDB`);
	} catch (e) {
		console.error('[persistence] ‚ùå Erreur chargement MongoDB:', e);
	}
}

// üÜï ARCHITECTURE "BO√éTE AUX LETTRES" : Le serveur local aspire les commandes et leur donne un ID
async function smartSyncWithMongoDB() {
	try {
		// 1. ASPIRER les commandes client de la "bo√Æte aux lettres" MongoDB
		// On cherche UNIQUEMENT les commandes avec waitingForPos=true et processedByPos=false
		// Ces commandes n'ont PAS d'ID (le POS local va leur en donner un)
		const waitingOrders = await dbManager.orders.find({
			waitingForPos: true,
			processedByPos: { $ne: true }, // Pas encore trait√©es
			$or: [{ id: null }, { id: { $exists: false } }], // Pas d'ID officiel
			source: 'client'
		}).toArray();

		console.log(`[sync] üì¨ ${waitingOrders.length} commande(s) en attente dans la bo√Æte aux lettres MongoDB`);

		// 2. TRAITER chaque commande : lui donner un ID local et la marquer comme trait√©e
		let processedCount = 0;
		for (const mongoOrder of waitingOrders) {
			// V√©rifier si cette commande existe d√©j√† localement (√©viter doublons)
			const existingLocal = dataStore.orders.find(o =>
				o.tempId === mongoOrder.tempId ||
				(o.id && o.id === mongoOrder.id)
			);

			if (!existingLocal) {
				// üÜï LE POS LOCAL DONNE L'ID (source de v√©rit√©)
				const localId = dataStore.nextOrderId++;
				mongoOrder.id = localId;
				mongoOrder.waitingForPos = false; // Plus en attente
				mongoOrder.processedByPos = true; // Trait√©e par le POS
				delete mongoOrder._id; // Supprimer _id MongoDB avant ajout local

				// Ajouter au datastore local
				dataStore.orders.push(mongoOrder);
				processedCount++;
				
				console.log(`[sync] ‚úÖ Commande ${mongoOrder.tempId} ‚Üí ID #${localId} (aspir√©e et trait√©e)`);
				
				// Marquer comme trait√©e dans MongoDB (pour ne pas la reprendre)
				try {
					await dbManager.orders.updateOne(
						{ tempId: mongoOrder.tempId },
						{ 
							$set: { 
								id: localId,
								processedByPos: true,
								waitingForPos: false
							}
						}
					);
				} catch (e) {
					console.error(`[sync] ‚ö†Ô∏è Erreur marquage commande ${mongoOrder.tempId} comme trait√©e:`, e.message);
				}
			} else {
				console.log(`[sync] ‚è≠Ô∏è Commande ${mongoOrder.tempId} d√©j√† pr√©sente localement, ignor√©e`);
			}
		}

		// üÜï Le serveur local est la SEULE source de v√©rit√©
		// On ne r√©cup√®re PAS les commandes depuis MongoDB (sauf commandes client en attente)
		// Si les fichiers JSON disent "0 commandes", alors il y a 0 commandes

		// 3. Synchroniser les compteurs si n√©cessaire
		const countersDoc = await dbManager.counters.findOne({ type: 'global' });
		if (countersDoc) {
			// Utiliser le max entre local et cloud
			const localMaxId = dataStore.orders.length > 0
				? Math.max(...dataStore.orders.map(o => o.id || 0))
				: 0;
			const cloudMaxId = countersDoc.nextOrderId || 1;

			dataStore.nextOrderId = Math.max(localMaxId + 1, cloudMaxId);
			dataStore.nextBillId = Math.max(dataStore.nextBillId, countersDoc.nextBillId || 1);
			dataStore.nextServiceId = Math.max(dataStore.nextServiceId, countersDoc.nextServiceId || 1);
			dataStore.nextClientId = Math.max(dataStore.nextClientId, countersDoc.nextClientId || 1);

			console.log(`[sync] üî¢ Compteurs synchronis√©s: nextOrderId=${dataStore.nextOrderId}`);
		}

		// 4. Charger les clients cr√©dit (backup)
		const clients = await dbManager.clientCredits.find({}).toArray();
		if (clients.length > 0) {
			// Merger sans √©craser
			for (const client of clients) {
				const existing = dataStore.clientCredits.find(c => c.id === client.id);
				if (!existing) {
					dataStore.clientCredits.push(client);
					console.log(`[sync] üë§ Client ${client.name} ajout√© depuis MongoDB`);
				}
			}
		}

		// üÜï PAS DE NETTOYAGE AUTOMATIQUE : Les commandes dans MongoDB sont soit :
		// - En attente (waitingForPos=true) ‚Üí seront aspir√©es par le POS
		// - Trait√©es (processedByPos=true) ‚Üí peuvent rester comme backup
		// Le POS local est la source de v√©rit√©, MongoDB est juste la bo√Æte aux lettres + backup

		console.log(`[sync] ‚úÖ Synchronisation termin√©e: ${processedCount} commande(s) aspir√©e(s) et trait√©e(s)`);

	} catch (e) {
		console.error('[sync] ‚ùå Erreur synchronisation intelligente:', e);
	}
}

async function saveToMongoDB() {
	try {
		if (!dbManager.db) {
			console.log('[sync] ‚ö†Ô∏è MongoDB non connect√©, synchronisation ignor√©e');
			return;
		}
		
		// üÜï SYNCHRONISATION INTELLIGENTE : G√©rer les resets de compteur intelligemment
		const countersDoc = await dbManager.counters.findOne({ type: 'global' });
		if (countersDoc && countersDoc.nextOrderId === 1) {
			// Calculer le max ID existant dans m√©moire et MongoDB
			const maxOrderId = dataStore.orders.length > 0
				? Math.max(...dataStore.orders.map(o => o.id || 0))
				: 0;

			const mongoOrders = await dbManager.orders.find({}).toArray();
			const maxMongoOrderId = mongoOrders.length > 0
				? Math.max(...mongoOrders.map(o => o.id || 0))
				: 0;

			const globalMaxId = Math.max(maxOrderId, maxMongoOrderId);

			if (globalMaxId > 0) {
				// üÜï CAS NORMAL : Synchroniser le compteur au lieu de reset destructeur
				console.log(`[sync] üîÑ SYNC COMPTEUR : nextOrderId 1 ‚Üí ${globalMaxId + 1} (max ID trouv√©: ${globalMaxId})`);
				await dbManager.counters.updateOne(
					{ type: 'global' },
					{ $set: { nextOrderId: globalMaxId + 1 } }
				);
				dataStore.nextOrderId = globalMaxId + 1;

				// üÜï Nettoyer automatiquement les anciennes entr√©es tempId des commandes confirm√©es
				const confirmedTempIds = new Set(
					[...dataStore.orders, ...mongoOrders]
						.filter(o => o.id && o.originalTempId && o.source === 'pos')
						.map(o => o.originalTempId)
				);

				if (confirmedTempIds.size > 0) {
					console.log(`[sync] üßπ Nettoyage automatique : ${confirmedTempIds.size} ancienne(s) entr√©e(s) tempId confirm√©e(s)`);
					let cleanedCount = 0;
					for (const tempId of confirmedTempIds) {
						const deleteResult = await dbManager.orders.deleteMany({
							tempId: tempId,
							$or: [{ id: null }, { id: { $exists: false } }] // Supprimer seulement les entr√©es sans ID officiel
						});
						cleanedCount += deleteResult.deletedCount || 0;
					}
					console.log(`[sync] üóëÔ∏è ${cleanedCount} ancienne(s) entr√©e(s) tempId supprim√©e(s)`);
				}

				console.log(`[sync] ‚úÖ Synchronisation intelligente termin√©e - Commandes pr√©serv√©es`);
				return; // Pas de sync normale, on vient de synchroniser intelligemment
			}
		}
		
		console.log('[sync] ‚òÅÔ∏è Synchronisation vers MongoDB (backup)...');
		
		// üÜï ARCHITECTURE "BO√éTE AUX LETTRES" : Le serveur local NE sauvegarde PAS les commandes client dans MongoDB
		// Les commandes client arrivent via le serveur cloud et sont aspir√©es par smartSyncWithMongoDB()
		// Une fois trait√©es (ID attribu√©), elles restent UNIQUEMENT dans le JSON local (source de v√©rit√©)
		// MongoDB ne contient QUE :
		// 1. Commandes client EN ATTENTE (d√©pos√©es par le serveur cloud, waitingForPos=true)
		// 2. Backups archiv√©es (pour dashboard)
		
		// üÜï On ne sauvegarde PAS les commandes actives dans MongoDB
		// Le serveur local est la source de v√©rit√©, MongoDB est juste la bo√Æte aux lettres
		
		// Synchroniser les commandes archiv√©es
		if (dataStore.archivedOrders.length > 0) {
			for (const order of dataStore.archivedOrders) {
				// üÜï CORRECTION : Supprimer _id MongoDB avant replaceOne
				const orderToSave = { ...order };
				delete orderToSave._id;
				
				await dbManager.archivedOrders.replaceOne(
					{ id: order.id },
					orderToSave,
					{ upsert: true }
				);
			}
			console.log(`[sync] ‚òÅÔ∏è ${dataStore.archivedOrders.length} commandes archiv√©es synchronis√©es`);

			// üÜï SUPPRIMER les commandes archiv√©es de la collection orders principale
			// pour √©viter qu'elles r√©apparaissent au red√©marrage
			if (dataStore.archivedOrders.length > 0) {
				const archivedIds = dataStore.archivedOrders.map(o => o.id);
				const deleteResult = await dbManager.orders.deleteMany({
					id: { $in: archivedIds }
				});
				console.log(`[sync] üóëÔ∏è ${deleteResult.deletedCount} commande(s) supprim√©e(s) de orders (maintenant archiv√©es)`);
			}
		}

		// Synchroniser les factures
		if (dataStore.bills.length > 0) {
			for (const bill of dataStore.bills) {
				// üÜï CORRECTION : Supprimer _id MongoDB avant replaceOne
				const billToSave = { ...bill };
				delete billToSave._id;
				
				await dbManager.bills.replaceOne(
					{ id: bill.id },
					billToSave,
					{ upsert: true }
				);
			}
			console.log(`[sync] ‚òÅÔ∏è ${dataStore.bills.length} factures synchronis√©es`);
		}
		
		// Synchroniser les factures archiv√©es
		if (dataStore.archivedBills.length > 0) {
			for (const bill of dataStore.archivedBills) {
				// üÜï CORRECTION : Supprimer _id MongoDB avant replaceOne
				const billToSave = { ...bill };
				delete billToSave._id;
				
				await dbManager.archivedBills.replaceOne(
					{ id: bill.id },
					billToSave,
					{ upsert: true }
				);
			}
			console.log(`[sync] ‚òÅÔ∏è ${dataStore.archivedBills.length} factures archiv√©es synchronis√©es`);
		}
		
		// Synchroniser les demandes de service
		if (dataStore.serviceRequests.length > 0) {
			for (const service of dataStore.serviceRequests) {
				// üÜï CORRECTION : Supprimer _id MongoDB avant replaceOne
				const serviceToSave = { ...service };
				delete serviceToSave._id;
				
				await dbManager.services.replaceOne(
					{ id: service.id },
					serviceToSave,
					{ upsert: true }
				);
			}
			console.log(`[sync] ‚òÅÔ∏è ${dataStore.serviceRequests.length} services synchronis√©s`);
		}
		
		// Synchroniser les clients cr√©dit
		if (dataStore.clientCredits.length > 0) {
			for (const client of dataStore.clientCredits) {
				// üÜï CORRECTION : Supprimer _id MongoDB avant replaceOne
				const clientToSave = { ...client };
				delete clientToSave._id;
				
				await dbManager.clientCredits.replaceOne(
					{ id: client.id },
					clientToSave,
					{ upsert: true }
				);
			}
			console.log(`[sync] ‚òÅÔ∏è ${dataStore.clientCredits.length} clients cr√©dit synchronis√©s`);
		}
		
		// Mise √† jour des compteurs
		await dbManager.counters.updateOne(
			{ type: 'global' },
			{ 
				$set: { 
					nextOrderId: dataStore.nextOrderId,
					nextBillId: dataStore.nextBillId,
					nextServiceId: dataStore.nextServiceId,
					nextClientId: dataStore.nextClientId,
					lastSynced: new Date().toISOString()
				} 
			},
			{ upsert: true }
		);

		console.log('[sync] ‚òÅÔ∏è ‚úÖ Synchronisation MongoDB termin√©e');
	} catch (e) {
		console.error('[sync] ‚ùå Erreur synchronisation MongoDB:', e);
		// Ne pas bloquer le POS en cas d'erreur cloud
		throw e; // Re-lancer pour que le catch dans savePersistedData le g√®re
	}
}

// --- LOGIQUE JSON (LOCAL) ---

async function loadFromJSON() {
	try {
		await ensureDir(dataStore.DATA_DIR);
		
		// Charger les commandes
		if (fs.existsSync(dataStore.ORDERS_FILE)) {
			const data = await fsp.readFile(dataStore.ORDERS_FILE, 'utf8');
			const loadedOrders = JSON.parse(data);
			dataStore.orders.length = 0;
			dataStore.orders.push(...loadedOrders);
			console.log(`[persistence] üè† ${dataStore.orders.length} commandes charg√©es`);
		}
		
		// Charger les commandes archiv√©es
		if (fs.existsSync(dataStore.ARCHIVED_ORDERS_FILE)) {
			const data = await fsp.readFile(dataStore.ARCHIVED_ORDERS_FILE, 'utf8');
			const loadedArchived = JSON.parse(data);
			dataStore.archivedOrders.length = 0;
			dataStore.archivedOrders.push(...loadedArchived);
			console.log(`[persistence] üè† ${dataStore.archivedOrders.length} commandes archiv√©es charg√©es`);
		}
		
		// Charger les factures
		if (fs.existsSync(dataStore.BILLS_FILE)) {
			const data = await fsp.readFile(dataStore.BILLS_FILE, 'utf8');
			const loadedBills = JSON.parse(data);
			dataStore.bills.length = 0;
			dataStore.bills.push(...loadedBills);
			console.log(`[persistence] üè† ${dataStore.bills.length} factures charg√©es`);
		}
		
		// Charger les factures archiv√©es
		if (fs.existsSync(dataStore.ARCHIVED_BILLS_FILE)) {
			const data = await fsp.readFile(dataStore.ARCHIVED_BILLS_FILE, 'utf8');
			const loadedArchivedBills = JSON.parse(data);
			dataStore.archivedBills.length = 0;
			dataStore.archivedBills.push(...loadedArchivedBills);
			console.log(`[persistence] üè† ${dataStore.archivedBills.length} factures archiv√©es charg√©es`);
		}
		
		// Charger les demandes de service
		if (fs.existsSync(dataStore.SERVICES_FILE)) {
			const data = await fsp.readFile(dataStore.SERVICES_FILE, 'utf8');
			const loadedServices = JSON.parse(data);
			dataStore.serviceRequests.length = 0;
			dataStore.serviceRequests.push(...loadedServices);
			console.log(`[persistence] üè† ${dataStore.serviceRequests.length} demandes de service charg√©es`);
		}
		
		// Charger les compteurs
		if (fs.existsSync(dataStore.COUNTERS_FILE)) {
			const data = await fsp.readFile(dataStore.COUNTERS_FILE, 'utf8');
			const counters = JSON.parse(data);
			dataStore.nextOrderId = counters.nextOrderId || 1;
			dataStore.nextBillId = counters.nextBillId || 1;
			dataStore.nextServiceId = counters.nextServiceId || 1;
			dataStore.nextClientId = counters.nextClientId || 1;
			console.log(`[persistence] üè† Compteurs charg√©s: orderId=${dataStore.nextOrderId}, billId=${dataStore.nextBillId}, serviceId=${dataStore.nextServiceId}, clientId=${dataStore.nextClientId}`);
		}
		
		// Charger les clients cr√©dit
		if (fs.existsSync(dataStore.CLIENT_CREDITS_FILE)) {
			const data = await fsp.readFile(dataStore.CLIENT_CREDITS_FILE, 'utf8');
			const loadedClients = JSON.parse(data);
			dataStore.clientCredits.length = 0;
			dataStore.clientCredits.push(...loadedClients);
			console.log(`[persistence] üè† ${dataStore.clientCredits.length} clients cr√©dit charg√©s`);
		} else {
			// Cr√©er le fichier vide si inexistant
			await fsp.writeFile(dataStore.CLIENT_CREDITS_FILE, '[]', 'utf8');
			console.log(`[persistence] üè† Fichier client_credits.json cr√©√© (vide)`);
		}
	} catch (e) {
		console.error('[persistence] üè† Erreur chargement donn√©es JSON:', e);
	}
}

async function saveToJSON() {
	try {
		await ensureDir(dataStore.DATA_DIR);
		
		// Sauvegarder les commandes
		await fsp.writeFile(dataStore.ORDERS_FILE, JSON.stringify(dataStore.orders, null, 2), 'utf8');
		
		// Sauvegarder les commandes archiv√©es
		await fsp.writeFile(dataStore.ARCHIVED_ORDERS_FILE, JSON.stringify(dataStore.archivedOrders, null, 2), 'utf8');
		
		// Sauvegarder les factures
		await fsp.writeFile(dataStore.BILLS_FILE, JSON.stringify(dataStore.bills, null, 2), 'utf8');
		
		// Sauvegarder les factures archiv√©es
		await fsp.writeFile(dataStore.ARCHIVED_BILLS_FILE, JSON.stringify(dataStore.archivedBills, null, 2), 'utf8');
		
		// Sauvegarder les demandes de service
		await fsp.writeFile(dataStore.SERVICES_FILE, JSON.stringify(dataStore.serviceRequests, null, 2), 'utf8');
		
		// Sauvegarder les compteurs
		const counters = {
			nextOrderId: dataStore.nextOrderId,
			nextBillId: dataStore.nextBillId,
			nextServiceId: dataStore.nextServiceId,
			nextClientId: dataStore.nextClientId,
			lastSaved: new Date().toISOString()
		};
		await fsp.writeFile(dataStore.COUNTERS_FILE, JSON.stringify(counters, null, 2), 'utf8');
		
		// Sauvegarder les clients cr√©dit
		await fsp.writeFile(dataStore.CLIENT_CREDITS_FILE, JSON.stringify(dataStore.clientCredits, null, 2), 'utf8');
		
		console.log(`[persistence] üè† Donn√©es sauvegard√©es: ${dataStore.orders.length} commandes, ${dataStore.bills.length} factures, ${dataStore.clientCredits.length} clients cr√©dit`);
	} catch (e) {
		console.error('[persistence] üè† Erreur sauvegarde donn√©es JSON:', e);
	}
}

module.exports = {
	ensureDir,
	loadPersistedData,
	savePersistedData,
	loadFromMongoDB, // Pour compatibilit√© serveur cloud
	smartSyncWithMongoDB // üÜï Synchronisation intelligente
};
