// üìÅ Gestionnaire de fichiers JSON
// G√®re la sauvegarde et le chargement des donn√©es persistantes

const fs = require('fs');
const fsp = fs.promises;
const dataStore = require('../data');
const dbManager = require('./dbManager');

// Cr√©er un dossier s'il n'existe pas
async function ensureDir(p) {
	try {
		await fsp.mkdir(p, { recursive: true });
	} catch (e) {
		// Dossier existe d√©j√†, ignore
	}
}

// üíæ Charger les donn√©es persistantes (d√©tecte Cloud vs Local)
async function loadPersistedData() {
	console.log('[persistence] üîÑ Chargement des donn√©es persist√©es...');

	if (dbManager.isCloud) {
		// üÜï SERVEUR CLOUD : Charger UNIQUEMENT depuis MongoDB (stateless)
		if (dbManager.db) {
			console.log('[persistence] ‚òÅÔ∏è Serveur cloud d√©tect√© - Chargement depuis MongoDB...');
			await loadFromMongoDB();
			console.log('[persistence] ‚úÖ Donn√©es charg√©es depuis MongoDB');
		} else {
			console.log('[persistence] ‚ö†Ô∏è Serveur cloud mais MongoDB non disponible - Donn√©es vides');
		}
	} else {
		// üÜï SERVEUR LOCAL = SOURCE DE VERITE : TOUJOURS charger depuis JSON local d'abord
		await loadFromJSON();
		console.log('[persistence] ‚úÖ Donn√©es charg√©es depuis fichiers locaux');

		// Puis synchroniser intelligemment avec MongoDB si disponible (pour commandes clients + backup)
		if (dbManager.db) {
			console.log('[persistence] ‚òÅÔ∏è Synchronisation intelligente avec MongoDB...');
			await smartSyncWithMongoDB();
			console.log('[persistence] ‚úÖ Synchronisation termin√©e');
		} else {
			console.log('[persistence] ‚ÑπÔ∏è MongoDB non disponible - fonctionnement en mode local seulement');
		}
	}
}

// üíæ Sauvegarder les donn√©es (Cloud = Stateless, Local = Statefull)
async function savePersistedData() {
	if (dbManager.isCloud) {
		// üÜï SERVEUR CLOUD : STATELESS - PAS de sauvegarde JSON locale
		// MAIS sauvegarde quand m√™me dans MongoDB pour les donn√©es re√ßues
		if (dbManager.db) {
			saveToMongoDB().catch(e => {
				console.error('[sync] ‚ö†Ô∏è Erreur sync MongoDB cloud:', e.message);
			});
		}
		return;
	} else {
		// SERVEUR LOCAL : Sauvegarde JSON locale + sync MongoDB
		try {
			await saveToJSON();
		} catch (e) {
			console.error('[persistence] ‚ùå Erreur sauvegarde JSON local:', e.message);
		}

		// Sync vers MongoDB (non-bloquant)
		if (dbManager.db) {
			saveToMongoDB().catch(e => {
				console.error('[sync] ‚ö†Ô∏è Erreur sync MongoDB:', e.message);
			});
		}
	}
}

// Fonction supprim√©e - le serveur cloud est maintenant stateless

// --- LOGIQUE MONGODB (CLOUD) ---

async function loadFromMongoDB() {
	try {
		console.log('[persistence] ‚òÅÔ∏è Chargement des donn√©es depuis MongoDB...');
		
		// Charger les commandes
		const orders = await dbManager.orders.find({}).toArray();

		// üÜï SOLUTION : Identifier les commandes confirm√©es par leur originalTempId
		const confirmedTempIds = new Set(
			orders
				.filter(o => o.id && o.originalTempId && o.source === 'pos')
				.map(o => o.originalTempId)
		);

		// üÜï Filtrer : exclure les commandes client qui ont d√©j√† √©t√© confirm√©es
		const filteredOrders = orders.filter(o => {
			// Si c'est une commande client avec tempId mais sans id, v√©rifier si elle a √©t√© confirm√©e
			if (o.tempId && (!o.id || o.id === null) && o.source === 'client') {
				if (confirmedTempIds.has(o.tempId)) {
					console.log(`[persistence] üßπ Commande client ${o.tempId} ignor√©e: d√©j√† confirm√©e (ID #${orders.find(oo => oo.originalTempId === o.tempId && oo.id)?.id})`);
					// Supprimer de MongoDB aussi
					dbManager.orders.deleteMany({ tempId: o.tempId }).catch(e =>
						console.error(`[persistence] ‚ö†Ô∏è Erreur suppression doublon: ${e.message}`)
					);
					return false;
				}
			}
			return true;
		});

		dataStore.orders.length = 0;
		dataStore.orders.push(...filteredOrders);
		
		// Charger les archives
		const archived = await dbManager.archivedOrders.find({}).toArray();
		dataStore.archivedOrders.length = 0;
		dataStore.archivedOrders.push(...archived);
		console.log(`[persistence] ‚òÅÔ∏è ${dataStore.archivedOrders.length} commandes archiv√©es charg√©es depuis MongoDB`);
		
		// Charger les factures
		const bills = await dbManager.bills.find({}).toArray();
		dataStore.bills.length = 0;
		dataStore.bills.push(...bills);
		
		const archivedBills = await dbManager.archivedBills.find({}).toArray();
		dataStore.archivedBills.length = 0;
		dataStore.archivedBills.push(...archivedBills);
		
		// Charger les services
		const services = await dbManager.services.find({}).toArray();
		dataStore.serviceRequests.length = 0;
		dataStore.serviceRequests.push(...services);
		
		// Charger les compteurs (un seul doc)
		const countersDoc = await dbManager.counters.findOne({ type: 'global' });
		if (countersDoc) {
			dataStore.nextOrderId = countersDoc.nextOrderId || 1;
			dataStore.nextBillId = countersDoc.nextBillId || 1;
			dataStore.nextServiceId = countersDoc.nextServiceId || 1;
			dataStore.nextClientId = countersDoc.nextClientId || 1;
		}
		
		// Charger les clients cr√©dit
		const clients = await dbManager.clientCredits.find({}).toArray();
		dataStore.clientCredits.length = 0;
		dataStore.clientCredits.push(...clients);
		
		console.log(`[persistence] ‚òÅÔ∏è ‚úÖ ${dataStore.orders.length} commandes et ${dataStore.clientCredits.length} clients charg√©s depuis MongoDB`);
	} catch (e) {
		console.error('[persistence] ‚ùå Erreur chargement MongoDB:', e);
	}
}

// üÜï FONCTION D'ASPIRATION : R√©cup√®re les commandes de la bo√Æte aux lettres MongoDB
// Peut √™tre appel√©e au d√©marrage ET p√©riodiquement (polling)
async function pullFromMailbox() {
	if (!dbManager.db) {
		return 0; // MongoDB non disponible
	}

	try {
		// 1. SCAN de la bo√Æte aux lettres MongoDB
		const waitingOrders = await dbManager.orders.find({
			waitingForPos: true,
			processedByPos: { $ne: true }, // Pas encore trait√©es
			$or: [{ id: null }, { id: { $exists: false } }], // Pas d'ID officiel
			source: 'client'
		}).toArray();

		if (waitingOrders.length === 0) {
			return 0; // Bo√Æte aux lettres vide
		}

		console.log(`[sync] üîç Scan de la bo√Æte aux lettres MongoDB...`);
		console.log(`[sync] üì¨ ${waitingOrders.length} nouvelle(s) commande(s) trouv√©e(s)`);

		// 2. TRAITER chaque commande : lui donner un ID local et la marquer comme trait√©e
		let processedCount = 0;
		for (const mongoOrder of waitingOrders) {
			// üÜï V√âRIFICATION ANTI-DOUBLON : V√©rifier si cette commande existe d√©j√† localement
			// Protection contre les micro-coupures r√©seau ou red√©marrages
			const existingLocal = dataStore.orders.find(o =>
				o.tempId === mongoOrder.tempId ||
				(o.id && o.id === mongoOrder.id) ||
				(o.tempId && mongoOrder.tempId && o.tempId === mongoOrder.tempId)
			);

			if (existingLocal) {
				console.log(`[sync] ‚è≠Ô∏è Commande ${mongoOrder.tempId} d√©j√† pr√©sente localement (ID: ${existingLocal.id || 'N/A'}), ignor√©e`);
				// Marquer quand m√™me comme trait√©e dans MongoDB si elle a d√©j√† un ID
				if (existingLocal.id) {
					try {
						await dbManager.orders.updateOne(
							{ tempId: mongoOrder.tempId },
							{ 
								$set: { 
									id: existingLocal.id,
									processedByPos: true,
									waitingForPos: false
								}
							}
						);
					} catch (e) {
						// Ignorer les erreurs de mise √† jour
					}
				}
				continue;
			}

			// üÜï LE POS LOCAL DONNE L'ID (source de v√©rit√©)
			const localId = dataStore.nextOrderId++;
			mongoOrder.id = localId;
			mongoOrder.waitingForPos = false; // Plus en attente
			mongoOrder.processedByPos = true; // Trait√©e par le POS
			delete mongoOrder._id; // Supprimer _id MongoDB avant ajout local

			// Ajouter au datastore local
			dataStore.orders.push(mongoOrder);
			processedCount++;
			
			console.log(`[sync] ‚úçÔ∏è Attribution ID #${localId} √† ${mongoOrder.tempId}. Enregistr√© localement.`);
			
			// üÜï DOUBLE VALIDATION MONGODB : Marquer comme trait√©e avec les 3 champs requis
			try {
				const updateResult = await dbManager.orders.updateOne(
					{ tempId: mongoOrder.tempId },
					{ 
						$set: { 
							id: localId, // ID d√©finitif du POS
							processedByPos: true, // Trait√©e par le POS
							waitingForPos: false // Plus en attente
						}
					}
				);
				if (updateResult.modifiedCount > 0) {
					console.log(`[sync] ‚úâÔ∏è Bo√Æte aux lettres : Commande ${mongoOrder.tempId} marqu√©e comme trait√©e (ID #${localId})`);
				}
			} catch (e) {
				console.error(`[sync] ‚ö†Ô∏è Erreur marquage commande ${mongoOrder.tempId} comme trait√©e:`, e.message);
			}
		}

		// Sauvegarder les nouvelles commandes dans le JSON local
		if (processedCount > 0) {
			try {
				await saveToJSON();
				console.log(`[sync] üíæ ${processedCount} commande(s) sauvegard√©e(s) en JSON local`);
			} catch (e) {
				console.error(`[sync] ‚ö†Ô∏è Erreur sauvegarde JSON:`, e.message);
			}
		}

		return processedCount;
	} catch (e) {
		console.error('[sync] ‚ùå Erreur aspiration bo√Æte aux lettres:', e);
		return 0;
	}
}

// üÜï SYNCHRONISATION INTELLIGENTE : Ne pas √©craser l'√©tat local
async function smartSyncWithMongoDB() {
	try {
		// 1. ASPIRER les commandes de la bo√Æte aux lettres (au d√©marrage)
		const processedCount = await pullFromMailbox();

		// üÜï Le serveur local est la SEULE source de v√©rit√©
		// On ne r√©cup√®re PAS les commandes depuis MongoDB (sauf commandes client en attente)
		// Si les fichiers JSON disent "0 commandes", alors il y a 0 commandes

		// 3. Synchroniser les compteurs si n√©cessaire
		const countersDoc = await dbManager.counters.findOne({ type: 'global' });
		if (countersDoc) {
			// Utiliser le max entre local et cloud
			const localMaxId = dataStore.orders.length > 0
				? Math.max(...dataStore.orders.map(o => o.id || 0))
				: 0;
			const cloudMaxId = countersDoc.nextOrderId || 1;

			dataStore.nextOrderId = Math.max(localMaxId + 1, cloudMaxId);
			dataStore.nextBillId = Math.max(dataStore.nextBillId, countersDoc.nextBillId || 1);
			dataStore.nextServiceId = Math.max(dataStore.nextServiceId, countersDoc.nextServiceId || 1);
			dataStore.nextClientId = Math.max(dataStore.nextClientId, countersDoc.nextClientId || 1);

			console.log(`[sync] üî¢ Compteurs synchronis√©s: nextOrderId=${dataStore.nextOrderId}`);
		}

		// 4. Charger les clients cr√©dit (backup)
		const clients = await dbManager.clientCredits.find({}).toArray();
		if (clients.length > 0) {
			// Merger sans √©craser
			for (const client of clients) {
				const existing = dataStore.clientCredits.find(c => c.id === client.id);
				if (!existing) {
					dataStore.clientCredits.push(client);
					console.log(`[sync] üë§ Client ${client.name} ajout√© depuis MongoDB`);
				}
			}
		}

		// üÜï PAS DE NETTOYAGE AUTOMATIQUE : Les commandes dans MongoDB sont soit :
		// - En attente (waitingForPos=true) ‚Üí seront aspir√©es par le POS
		// - Trait√©es (processedByPos=true) ‚Üí peuvent rester comme backup
		// Le POS local est la source de v√©rit√©, MongoDB est juste la bo√Æte aux lettres + backup

		console.log(`[sync] ‚úÖ Synchronisation termin√©e: ${processedCount} commande(s) aspir√©e(s) et trait√©e(s)`);

	} catch (e) {
		console.error('[sync] ‚ùå Erreur synchronisation intelligente:', e);
	}
}

async function saveToMongoDB() {
	try {
		if (!dbManager.db) {
			console.log('[sync] ‚ö†Ô∏è MongoDB non connect√©, synchronisation ignor√©e');
			return;
		}
		
		// üÜï SYNCHRONISATION INTELLIGENTE : G√©rer les resets de compteur intelligemment
		const countersDoc = await dbManager.counters.findOne({ type: 'global' });
		if (countersDoc && countersDoc.nextOrderId === 1) {
			// Calculer le max ID existant dans m√©moire et MongoDB
			const maxOrderId = dataStore.orders.length > 0
				? Math.max(...dataStore.orders.map(o => o.id || 0))
				: 0;

			const mongoOrders = await dbManager.orders.find({}).toArray();
			const maxMongoOrderId = mongoOrders.length > 0
				? Math.max(...mongoOrders.map(o => o.id || 0))
				: 0;

			const globalMaxId = Math.max(maxOrderId, maxMongoOrderId);

			if (globalMaxId > 0) {
				// üÜï CAS NORMAL : Synchroniser le compteur au lieu de reset destructeur
				console.log(`[sync] üîÑ SYNC COMPTEUR : nextOrderId 1 ‚Üí ${globalMaxId + 1} (max ID trouv√©: ${globalMaxId})`);
				await dbManager.counters.updateOne(
					{ type: 'global' },
					{ $set: { nextOrderId: globalMaxId + 1 } }
				);
				dataStore.nextOrderId = globalMaxId + 1;

				// üÜï Nettoyer automatiquement les anciennes entr√©es tempId des commandes confirm√©es
				const confirmedTempIds = new Set(
					[...dataStore.orders, ...mongoOrders]
						.filter(o => o.id && o.originalTempId && o.source === 'pos')
						.map(o => o.originalTempId)
				);

				if (confirmedTempIds.size > 0) {
					console.log(`[sync] üßπ Nettoyage automatique : ${confirmedTempIds.size} ancienne(s) entr√©e(s) tempId confirm√©e(s)`);
					let cleanedCount = 0;
					for (const tempId of confirmedTempIds) {
						const deleteResult = await dbManager.orders.deleteMany({
							tempId: tempId,
							$or: [{ id: null }, { id: { $exists: false } }] // Supprimer seulement les entr√©es sans ID officiel
						});
						cleanedCount += deleteResult.deletedCount || 0;
					}
					console.log(`[sync] üóëÔ∏è ${cleanedCount} ancienne(s) entr√©e(s) tempId supprim√©e(s)`);
				}

				console.log(`[sync] ‚úÖ Synchronisation intelligente termin√©e - Commandes pr√©serv√©es`);
				return; // Pas de sync normale, on vient de synchroniser intelligemment
			}
		}
		
		console.log('[sync] ‚òÅÔ∏è Synchronisation vers MongoDB (backup)...');
		
		// üÜï ARCHITECTURE "BO√éTE AUX LETTRES" : Le serveur local NE sauvegarde PAS les commandes client dans MongoDB
		// Les commandes client arrivent via le serveur cloud et sont aspir√©es par smartSyncWithMongoDB()
		// Une fois trait√©es (ID attribu√©), elles restent UNIQUEMENT dans le JSON local (source de v√©rit√©)
		// MongoDB ne contient QUE :
		// 1. Commandes client EN ATTENTE (d√©pos√©es par le serveur cloud, waitingForPos=true)
		// 2. Backups archiv√©es (pour dashboard)
		// 3. üÜï Commandes actives (pour que le dashboard admin en ligne puisse voir les tables non pay√©es)
		
		// üÜï CORRECTION : Synchroniser aussi les commandes actives pour le dashboard admin en ligne
		// Le serveur cloud a besoin de voir les commandes actives pour calculer les tables non pay√©es
		if (dataStore.orders.length > 0) {
			const activeOrders = dataStore.orders.filter(o => o.status !== 'archived');
			console.log(`[sync] üîç DEBUG: ${dataStore.orders.length} commandes totales, ${activeOrders.length} actives (status !== 'archived')`);
			
			let syncedCount = 0;
			let skippedCount = 0;
			
			for (const order of activeOrders) {
				// üÜï DEBUG: Log chaque commande avant synchronisation
				console.log(`[sync] üîç DEBUG: Commande id=${order.id || 'NULL'}, table=${order.table}, status=${order.status}, source=${order.source || 'undefined'}`);
				
				// üÜï CORRECTION : V√©rifier que la commande a un ID valide
				if (!order.id || order.id === null) {
					console.warn(`[sync] ‚ö†Ô∏è Commande ignor√©e (pas d'ID): table=${order.table}, tempId=${order.tempId || 'N/A'}, source=${order.source || 'undefined'}, status=${order.status}`);
					skippedCount++;
					continue; // Ignorer les commandes sans ID (commandes client en attente)
				}
				
				// üÜï CORRECTION : Supprimer _id MongoDB avant replaceOne
				const orderToSave = { ...order };
				delete orderToSave._id;
				
				try {
					const result = await dbManager.orders.replaceOne(
						{ id: order.id },
						orderToSave,
						{ upsert: true }
					);
					syncedCount++;
					console.log(`[sync] ‚úÖ Commande ${order.id} (table ${order.table}) synchronis√©e: ${result.upsertedCount > 0 ? 'cr√©√©e' : 'mise √† jour'}`);
				} catch (e) {
					console.error(`[sync] ‚ùå Erreur synchronisation commande ${order.id} (table ${order.table}):`, e.message);
					console.error(`[sync] ‚ùå Stack:`, e.stack);
				}
			}
			console.log(`[sync] ‚òÅÔ∏è ${syncedCount} commandes actives synchronis√©es vers MongoDB, ${skippedCount} ignor√©es (pas d'ID)`);
		} else {
			// üÜï Si le tableau est vide, supprimer toutes les commandes actives de MongoDB
			// (mais garder les commandes client en attente avec waitingForPos=true)
			const deleteResult = await dbManager.orders.deleteMany({
				status: { $ne: 'archived' },
				waitingForPos: { $ne: true } // Ne pas supprimer les commandes client en attente
			});
			if (deleteResult.deletedCount > 0) {
				console.log(`[sync] üóëÔ∏è ${deleteResult.deletedCount} commande(s) active(s) supprim√©e(s) de MongoDB (√©tat vide synchronis√©)`);
			}
		}
		
		// Synchroniser les commandes archiv√©es
		if (dataStore.archivedOrders.length > 0) {
			for (const order of dataStore.archivedOrders) {
				// üÜï CORRECTION : Supprimer _id MongoDB avant replaceOne
				const orderToSave = { ...order };
				delete orderToSave._id;
				
				await dbManager.archivedOrders.replaceOne(
					{ id: order.id },
					orderToSave,
					{ upsert: true }
				);
			}
			console.log(`[sync] ‚òÅÔ∏è ${dataStore.archivedOrders.length} commandes archiv√©es synchronis√©es`);
		} else {
			// üÜï Si le tableau est vide (apr√®s reset), supprimer toutes les archives de MongoDB
			// pour garantir que l'√©tat vide est bien synchronis√©
			const deleteResult = await dbManager.archivedOrders.deleteMany({});
			if (deleteResult.deletedCount > 0) {
				console.log(`[sync] üóëÔ∏è ${deleteResult.deletedCount} commande(s) archiv√©e(s) supprim√©e(s) de MongoDB (√©tat vide synchronis√©)`);
			}

			// üÜï SUPPRIMER les commandes archiv√©es de la collection orders principale
			// pour √©viter qu'elles r√©apparaissent au red√©marrage
			if (dataStore.archivedOrders.length > 0) {
				const archivedIds = dataStore.archivedOrders.map(o => o.id);
				const deleteResult = await dbManager.orders.deleteMany({
					id: { $in: archivedIds }
				});
				console.log(`[sync] üóëÔ∏è ${deleteResult.deletedCount} commande(s) supprim√©e(s) de orders (maintenant archiv√©es)`);
			}
		}

		// Synchroniser les factures
		if (dataStore.bills.length > 0) {
			for (const bill of dataStore.bills) {
				// üÜï CORRECTION : Supprimer _id MongoDB avant replaceOne
				const billToSave = { ...bill };
				delete billToSave._id;
				
				await dbManager.bills.replaceOne(
					{ id: bill.id },
					billToSave,
					{ upsert: true }
				);
			}
			console.log(`[sync] ‚òÅÔ∏è ${dataStore.bills.length} factures synchronis√©es`);
		}
		
		// Synchroniser les factures archiv√©es
		if (dataStore.archivedBills.length > 0) {
			for (const bill of dataStore.archivedBills) {
				// üÜï CORRECTION : Supprimer _id MongoDB avant replaceOne
				const billToSave = { ...bill };
				delete billToSave._id;
				
				await dbManager.archivedBills.replaceOne(
					{ id: bill.id },
					billToSave,
					{ upsert: true }
				);
			}
			console.log(`[sync] ‚òÅÔ∏è ${dataStore.archivedBills.length} factures archiv√©es synchronis√©es`);
		}
		
		// Synchroniser les demandes de service
		if (dataStore.serviceRequests.length > 0) {
			for (const service of dataStore.serviceRequests) {
				// üÜï CORRECTION : Supprimer _id MongoDB avant replaceOne
				const serviceToSave = { ...service };
				delete serviceToSave._id;
				
				await dbManager.services.replaceOne(
					{ id: service.id },
					serviceToSave,
					{ upsert: true }
				);
			}
			console.log(`[sync] ‚òÅÔ∏è ${dataStore.serviceRequests.length} services synchronis√©s`);
		}
		
		// Synchroniser les clients cr√©dit
		if (dataStore.clientCredits.length > 0) {
			for (const client of dataStore.clientCredits) {
				// üÜï CORRECTION : Supprimer _id MongoDB avant replaceOne
				const clientToSave = { ...client };
				delete clientToSave._id;
				
				await dbManager.clientCredits.replaceOne(
					{ id: client.id },
					clientToSave,
					{ upsert: true }
				);
			}
			console.log(`[sync] ‚òÅÔ∏è ${dataStore.clientCredits.length} clients cr√©dit synchronis√©s`);
		} else {
			// üÜï Si le tableau est vide (apr√®s reset), supprimer tous les cr√©dits de MongoDB
			// pour garantir que l'√©tat vide est bien synchronis√©
			const deleteResult = await dbManager.clientCredits.deleteMany({});
			if (deleteResult.deletedCount > 0) {
				console.log(`[sync] üóëÔ∏è ${deleteResult.deletedCount} cr√©dit(s) client(s) supprim√©(s) de MongoDB (√©tat vide synchronis√©)`);
			}
		}
		
		// Mise √† jour des compteurs
		await dbManager.counters.updateOne(
			{ type: 'global' },
			{ 
				$set: { 
					nextOrderId: dataStore.nextOrderId,
					nextBillId: dataStore.nextBillId,
					nextServiceId: dataStore.nextServiceId,
					nextClientId: dataStore.nextClientId,
					lastSynced: new Date().toISOString()
				} 
			},
			{ upsert: true }
		);

		console.log('[sync] ‚òÅÔ∏è ‚úÖ Synchronisation MongoDB termin√©e');
	} catch (e) {
		console.error('[sync] ‚ùå Erreur synchronisation MongoDB:', e);
		// Ne pas bloquer le POS en cas d'erreur cloud
		throw e; // Re-lancer pour que le catch dans savePersistedData le g√®re
	}
}

// --- LOGIQUE JSON (LOCAL) ---

async function loadFromJSON() {
	try {
		await ensureDir(dataStore.DATA_DIR);
		
		// Charger les commandes
		if (fs.existsSync(dataStore.ORDERS_FILE)) {
			const data = await fsp.readFile(dataStore.ORDERS_FILE, 'utf8');
			const loadedOrders = JSON.parse(data);
			dataStore.orders.length = 0;
			dataStore.orders.push(...loadedOrders);
			console.log(`[persistence] üè† ${dataStore.orders.length} commandes charg√©es`);
		}
		
		// Charger les commandes archiv√©es
		if (fs.existsSync(dataStore.ARCHIVED_ORDERS_FILE)) {
			const data = await fsp.readFile(dataStore.ARCHIVED_ORDERS_FILE, 'utf8');
			const loadedArchived = JSON.parse(data);
			dataStore.archivedOrders.length = 0;
			dataStore.archivedOrders.push(...loadedArchived);
			console.log(`[persistence] üè† ${dataStore.archivedOrders.length} commandes archiv√©es charg√©es`);
		}
		
		// Charger les factures
		if (fs.existsSync(dataStore.BILLS_FILE)) {
			const data = await fsp.readFile(dataStore.BILLS_FILE, 'utf8');
			const loadedBills = JSON.parse(data);
			dataStore.bills.length = 0;
			dataStore.bills.push(...loadedBills);
			console.log(`[persistence] üè† ${dataStore.bills.length} factures charg√©es`);
		}
		
		// Charger les factures archiv√©es
		if (fs.existsSync(dataStore.ARCHIVED_BILLS_FILE)) {
			const data = await fsp.readFile(dataStore.ARCHIVED_BILLS_FILE, 'utf8');
			const loadedArchivedBills = JSON.parse(data);
			dataStore.archivedBills.length = 0;
			dataStore.archivedBills.push(...loadedArchivedBills);
			console.log(`[persistence] üè† ${dataStore.archivedBills.length} factures archiv√©es charg√©es`);
		}
		
		// Charger les demandes de service
		if (fs.existsSync(dataStore.SERVICES_FILE)) {
			const data = await fsp.readFile(dataStore.SERVICES_FILE, 'utf8');
			const loadedServices = JSON.parse(data);
			dataStore.serviceRequests.length = 0;
			dataStore.serviceRequests.push(...loadedServices);
			console.log(`[persistence] üè† ${dataStore.serviceRequests.length} demandes de service charg√©es`);
		}
		
		// Charger les compteurs
		if (fs.existsSync(dataStore.COUNTERS_FILE)) {
			const data = await fsp.readFile(dataStore.COUNTERS_FILE, 'utf8');
			const counters = JSON.parse(data);
			dataStore.nextOrderId = counters.nextOrderId || 1;
			dataStore.nextBillId = counters.nextBillId || 1;
			dataStore.nextServiceId = counters.nextServiceId || 1;
			dataStore.nextClientId = counters.nextClientId || 1;
			console.log(`[persistence] üè† Compteurs charg√©s: orderId=${dataStore.nextOrderId}, billId=${dataStore.nextBillId}, serviceId=${dataStore.nextServiceId}, clientId=${dataStore.nextClientId}`);
		}
		
		// Charger les clients cr√©dit
		if (fs.existsSync(dataStore.CLIENT_CREDITS_FILE)) {
			const data = await fsp.readFile(dataStore.CLIENT_CREDITS_FILE, 'utf8');
			const loadedClients = JSON.parse(data);
			dataStore.clientCredits.length = 0;
			dataStore.clientCredits.push(...loadedClients);
			console.log(`[persistence] üè† ${dataStore.clientCredits.length} clients cr√©dit charg√©s`);
		} else {
			// Cr√©er le fichier vide si inexistant
			await fsp.writeFile(dataStore.CLIENT_CREDITS_FILE, '[]', 'utf8');
			console.log(`[persistence] üè† Fichier client_credits.json cr√©√© (vide)`);
		}
	} catch (e) {
		console.error('[persistence] üè† Erreur chargement donn√©es JSON:', e);
	}
}

async function saveToJSON() {
	try {
		await ensureDir(dataStore.DATA_DIR);
		
		// Sauvegarder les commandes
		await fsp.writeFile(dataStore.ORDERS_FILE, JSON.stringify(dataStore.orders, null, 2), 'utf8');
		
		// Sauvegarder les commandes archiv√©es
		await fsp.writeFile(dataStore.ARCHIVED_ORDERS_FILE, JSON.stringify(dataStore.archivedOrders, null, 2), 'utf8');
		
		// Sauvegarder les factures
		await fsp.writeFile(dataStore.BILLS_FILE, JSON.stringify(dataStore.bills, null, 2), 'utf8');
		
		// Sauvegarder les factures archiv√©es
		await fsp.writeFile(dataStore.ARCHIVED_BILLS_FILE, JSON.stringify(dataStore.archivedBills, null, 2), 'utf8');
		
		// Sauvegarder les demandes de service
		await fsp.writeFile(dataStore.SERVICES_FILE, JSON.stringify(dataStore.serviceRequests, null, 2), 'utf8');
		
		// Sauvegarder les compteurs
		const counters = {
			nextOrderId: dataStore.nextOrderId,
			nextBillId: dataStore.nextBillId,
			nextServiceId: dataStore.nextServiceId,
			nextClientId: dataStore.nextClientId,
			lastSaved: new Date().toISOString()
		};
		await fsp.writeFile(dataStore.COUNTERS_FILE, JSON.stringify(counters, null, 2), 'utf8');
		
		// Sauvegarder les clients cr√©dit
		await fsp.writeFile(dataStore.CLIENT_CREDITS_FILE, JSON.stringify(dataStore.clientCredits, null, 2), 'utf8');
		
		console.log(`[persistence] üè† Donn√©es sauvegard√©es: ${dataStore.orders.length} commandes, ${dataStore.bills.length} factures, ${dataStore.clientCredits.length} clients cr√©dit`);
	} catch (e) {
		console.error('[persistence] üè† Erreur sauvegarde donn√©es JSON:', e);
	}
}

module.exports = {
	ensureDir,
	loadPersistedData,
	savePersistedData,
	loadFromMongoDB, // Pour compatibilit√© serveur cloud
	smartSyncWithMongoDB, // üÜï Synchronisation intelligente
	pullFromMailbox // üÜï Fonction d'aspiration pour polling p√©riodique
};
